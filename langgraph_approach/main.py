import os
import ast
import json
from typing import TypedDict, List
from unittest.mock import patch, mock_open, MagicMock
import boto3
import configparser
from langchain_aws.chat_models import ChatBedrock
from langchain_core.messages import HumanMessage
from botocore.config import Config

# from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END

# --- 1. Define the State for the Graph ---
# This dictionary carries data between the nodes.

class GraphState(TypedDict):
    """
    Represents the state of our graph.

    Attributes:
        prompt: The user's initial request to generate code.
        generated_code: The Python code generated by the LLM.
        parse_error: Error message if the code has syntax errors. None otherwise.
        test_error: Error message from the testing/validation phase. None otherwise.
        max_retries: The maximum number of retries to prevent infinite loops.
        current_retry: The current attempt number.
    """
    prompt: str
    generated_code: str
    parse_error: str
    test_error: str
    max_retries: int
    current_retry: int

# --- 2. Define the Nodes (The Steps in the Flow) ---

def generate_code_node(state: GraphState):
    """
    Node to generate Python code based on the prompt and any previous errors.
    """
    print("--- GENERATING CODE ---")
    
    prompt = state["prompt"]
    retries = state["current_retry"]
    
    # Append error feedback to the prompt for self-correction
    error_feedback = ""
    if state.get("parse_error"):
        error_feedback = f"\n\nThe previous attempt failed with a syntax error: {state['parse_error']}. Please fix it."
    elif state.get("test_error"):
        error_feedback = f"\n\nThe previous attempt failed during testing: {state['test_error']}. Please fix the logic."
    
    full_prompt = f"""
    You are an expert Python programmer. Generate a single, self-contained Python script based on this request:
    ---
    {prompt}
    ---
    Guidelines:
    - If it is a TV schedules website, crawl the data for previous 'n' days, including the current day.
    - The script must use the 'requests' library for API calls and the 'os' and 'json' libraries for file handling.
    - If the data is hierarchical (e.g., shows with episodes), save it as `showname/episode_name.json`.
    - If the data is a flat list (e.g., movies), save it as `movies/movie_title.json`.
    - Sanitize filenames by replacing spaces with underscores and removing special characters.
    - The script should define a main function and call it under an `if __name__ == "__main__":` block.
    - Name the crawler code python file as site_name_api_crawler.py
    - Store the Json results in a folder named site_name_results/
    
    {error_feedback}
    
    Return only the raw Python code, without any markdown formatting (e.g., ```python).
    """

    # llm = ChatOpenAI(model="gpt-4o", temperature=0.2)

    os.environ["AWS_SHARED_CREDENTIALS_FILE"] = '~/.aws/credentials'
    os.environ["AWS_PROFILE"] = '536697239187-/AI-DEVELOPER'

    config = configparser.ConfigParser()
    config.read(os.path.expanduser('~/.aws/credentials'))

    profile = '536697239187-/AI-DEVELOPER'

    if profile in config:
        os.environ['AWS_ACCESS_KEY_ID'] = config[profile]['aws_access_key_id']
        os.environ['AWS_SECRET_ACCESS_KEY'] = config[profile]['aws_secret_access_key']
        if 'aws_session_token' in config[profile]:
            os.environ['AWS_SESSION_TOKEN'] = config[profile]['aws_session_token']

    region_name = 'us-east-1'
    session = boto3.Session(
        aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],
        aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'],
        aws_session_token=os.environ['AWS_SESSION_TOKEN'],
        region_name='us-east-1'
    )

    config = Config(
        read_timeout = 300, 
        retries = {
            'max_attempts' : 3
        }
    )

    bedrock_runtime = boto3.client("bedrock-runtime", region_name=region_name, config=config)

    llm = ChatBedrock(
        model_id="arn:aws:bedrock:us-east-1:536697239187:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0",
        client=bedrock_runtime,
        provider="anthropic",
        model_kwargs={
            "max_tokens": 64000,
            "anthropic_version": "bedrock-2023-05-31",
            "temperature": 0
        }
    )

    response = llm.invoke([full_prompt])
    
    state["generated_code"] = response.content
    state["current_retry"] += 1
    state["parse_error"] = None # Reset errors for the new code
    state["test_error"] = None
    
    return state

def parse_code_node(state: GraphState):
    """
    Node to check if the generated code is valid Python syntax.
    """
    print("--- PARSING CODE ---")
    try:
        ast.parse(state["generated_code"])
        print("Syntax is valid.")
        state["parse_error"] = None
    except Exception as e:
        print(f"Syntax error found: {e}")
        state["parse_error"] = f"Invalid Python syntax: {e}"
    return state

def test_code_node(state: GraphState):
    """
    Node to run the code in a mocked, safe environment to validate its behavior.
    """
    print("--- TESTING CODE ---")
    
    # This is a mock test. It does NOT execute the code directly on your machine.
    # It uses `unittest.mock` to simulate file/network operations and checks if the
    # code tried to perform the correct actions.
    
    code_to_test = state["generated_code"]
    
    # Mock the API response
    mock_api_response = MagicMock()
    mock_api_response.status_code = 200
    # mock_api_response.json.return_value = {
    #     "results": [
    #         {"title": "A New Hope", "episode_id": 4, "director": "George Lucas"},
    #         {"title": "The Empire Strikes Back", "episode_id": 5, "director": "Irvin Kershner"},
    #     ]
    # }
    
    # Use patch to intercept calls to requests, os, and open
    # This creates a "sandbox" for our test.
    with patch('requests.get', return_value=mock_api_response) as mock_get, \
         patch('os.makedirs') as mock_makedirs, \
         patch('builtins.open', mock_open()) as mock_file:
        
        try:
            # Execute the generated code in a restricted namespace
            exec_namespace = {}
            exec(code_to_test, exec_namespace)
            
            # --- Validation Checks ---
            # 1. Did it try to make the correct directory?
            # mock_makedirs.assert_called_with("movies", exist_ok=True)
            
            # 2. Did it try to fetch data from the API?
            # mock_get.assert_called_with("[https://swapi.dev/api/films/](https://swapi.dev/api/films/)")

            # 3. Did it try to create the correct files?
            # mock_file.assert_any_call("movies/A_New_Hope.json", "w")
            # mock_file.assert_any_call("movies/The_Empire_Strikes_Back.json", "w")
            
            print("All validation checks passed.")
            state["test_error"] = None

        except Exception as e:
            print(f"Test failed: {e}")
            state["test_error"] = f"Runtime or validation error: {e}"
            
    return state


# --- 3. Define the Edges (The Logic that Connects the Nodes) ---

def decide_after_parse(state: GraphState):
    """
    Router to decide the next step after parsing.
    If there's a parse error or we've hit max retries, go back to the generator.
    Otherwise, proceed to testing.
    """
    if state["parse_error"] or state["current_retry"] >= state["max_retries"]:
        print("--- ROUTING: PARSE FAILED, RETRYING ---")
        return "generator"
    else:
        print("--- ROUTING: PARSE OK, PROCEEDING TO TEST ---")
        return "tester"

def decide_after_test(state: GraphState):
    """
    Router to decide the next step after testing.
    If there's a test error or we've hit max retries, go back to the generator.
    Otherwise, the process is complete.
    """
    if state["test_error"] and state["current_retry"] < state["max_retries"]:
        print("--- ROUTING: TEST FAILED, RETRYING ---")
        return "generator"
    else:
        print("--- ROUTING: TEST PASSED OR MAX RETRIES, ENDING ---")
        return END

# --- 4. Assemble the Graph ---

workflow = StateGraph(GraphState)

# Add the nodes
workflow.add_node("generator", generate_code_node)
workflow.add_node("parser", parse_code_node)
workflow.add_node("tester", test_code_node)

# Set the entry point
workflow.set_entry_point("generator")

# Add the conditional edges
workflow.add_conditional_edges(
    "parser",
    decide_after_parse,
    {"generator": "generator", "tester": "tester"}
)
workflow.add_conditional_edges(
    "tester",
    decide_after_test,
    {"generator": "generator", END: END}
)

# Add the direct edge from generator to parser
workflow.add_edge('generator', 'parser')

# Compile the graph into a runnable object
app = workflow.compile()


# --- 5. Run the Graph ---

if __name__ == "__main__":
    with open("api-docs/ctv.txt", "r") as f:
        ctv_doc = f.read()
    USER_PROMPT = f"""
    Please create a Python script to crawl this website, providing the API documentation
    The filename should be the movie's title, sanitized.
    {ctv_doc}
    """
    
    # Set initial state and run the graph
    initial_state = {
        "prompt": USER_PROMPT,
        "generated_code": "",
        "parse_error": None,
        "test_error": None,
        "max_retries": 3,
        "current_retry": 0,
    }
    
    final_state = app.invoke(initial_state)
    
    print("\n\n--- FINAL RESULT ---")
    
    if final_state["test_error"] or final_state["parse_error"]:
        print("\nCode generation failed after multiple retries.")
        print(f"Last code attempt:\n\n{final_state['generated_code']}")
    else:
        print("\nCode generated and validated successfully!")
        
        # This is the "save code" step in your diagram
        final_code = final_state["generated_code"]
        with open("generated_api_crawler.py", "w") as f:
            f.write(final_code)
        
        print("\nFinal code saved to 'generated_api_crawler.py'")
        print("\n--- CODE ---")
        print(final_code)